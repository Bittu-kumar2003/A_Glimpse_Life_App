{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "mount_file_id": "1XXppOWVx5aDEAdgfikrcKwJmsGGuaid5",
      "authorship_tag": "ABX9TyMNmSowszrio2W1sNIYJKIv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bittu-kumar2003/A_Glimpse_Life_App/blob/master/Image_model_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM_Model**"
      ],
      "metadata": {
        "id": "dCU5Swm5-70_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKufAiis-aqA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Reshape, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_tif_image(file_path, target_size=(128, 128)):\n",
        "    img = load_img(file_path, color_mode='grayscale', target_size=target_size)\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "    return img\n",
        "\n",
        "def load_dataset_from_directory(directory, target_size=(128, 128)):\n",
        "    images = []\n",
        "    dates = []\n",
        "    stations = []\n",
        "\n",
        "    for file_name in sorted(os.listdir(directory)):\n",
        "        if file_name.endswith('.tif'):\n",
        "            try:\n",
        "                station = file_name[:-15]\n",
        "                date_str = file_name[-14:-4]\n",
        "                date = datetime.strptime(date_str, '%Y-%m-%d')\n",
        "\n",
        "                img_path = os.path.join(directory, file_name)\n",
        "                print(f\"Loading image: {img_path}\")\n",
        "                img = load_tif_image(img_path, target_size=target_size)\n",
        "                images.append(img)\n",
        "                dates.append(date)\n",
        "                stations.append(station)\n",
        "            except ValueError as e:\n",
        "                print(f\"Skipping file {file_name}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(dates), np.array(stations)\n",
        "\n",
        "def prepare_data(images, sequence_length=10, prediction_offsets=[1, 3, 5]):\n",
        "    X = []\n",
        "    y_targets = [[] for _ in prediction_offsets]\n",
        "    for i in range(len(images) - sequence_length - max(prediction_offsets) + 1):\n",
        "        X.append(images[i:i + sequence_length])\n",
        "        for j, offset in enumerate(prediction_offsets):\n",
        "            y_targets[j].append(images[i + sequence_length + offset - 1])\n",
        "    return np.array(X), [np.array(y) for y in y_targets]\n",
        "\n",
        "def create_lstm_model(sequence_length, image_shape, num_predictions):\n",
        "    model_input = Input(shape=(sequence_length, *image_shape))\n",
        "\n",
        "    x = Reshape((sequence_length, np.prod(image_shape)))(model_input)\n",
        "\n",
        "    x = LSTM(128, return_sequences=True)(x)\n",
        "    x = LSTM(128)(x)\n",
        "\n",
        "    outputs = []\n",
        "    for _ in range(num_predictions):\n",
        "        x_out = Dense(np.prod(image_shape), activation='sigmoid')(x)\n",
        "        output = Reshape(image_shape)(x_out)\n",
        "        outputs.append(output)\n",
        "\n",
        "    model = Model(inputs=model_input, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_next_images(model, input_sequence, num_predictions):\n",
        "    input_sequence = np.expand_dims(input_sequence, axis=0)\n",
        "    predicted_images = model.predict(input_sequence)\n",
        "    return [predicted.squeeze() for predicted in predicted_images]\n",
        "\n",
        "# Example usage\n",
        "directory = '/content/drive/MyDrive/Dataset_img/one_month_NO2_2019'\n",
        "stations = ['Delhi', 'Mumbai', 'Kolkata', 'Jaipur', 'Bengaluru', 'Bhopal', 'Chennai']\n",
        "target_size = (128, 128)\n",
        "sequence_length = 10\n",
        "prediction_offsets = [1, 3, 5]\n",
        "\n",
        "all_images, all_dates, all_stations = load_dataset_from_directory(directory, target_size=target_size)\n",
        "\n",
        "X, y_targets = prepare_data(all_images, sequence_length=sequence_length, prediction_offsets=prediction_offsets)\n",
        "\n",
        "image_shape = (128, 128, 1)\n",
        "num_predictions = len(prediction_offsets)\n",
        "model = create_lstm_model(sequence_length, image_shape, num_predictions)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model.fit(X, y_targets, epochs=12, batch_size=4, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "unique_stations = np.unique(all_stations)\n",
        "overall_y_true = [[] for _ in prediction_offsets]\n",
        "overall_y_pred = [[] for _ in prediction_offsets]\n",
        "\n",
        "for station in unique_stations:\n",
        "    station_indices = np.where(all_stations == station)[0]\n",
        "    if len(station_indices) > sequence_length + max(prediction_offsets) - 1:\n",
        "        index = station_indices[0]\n",
        "        input_sequence = X[index]\n",
        "        y_true_list = [y[index] for y in y_targets]\n",
        "        predicted_images = predict_next_images(model, input_sequence, num_predictions)\n",
        "\n",
        "        for i, (y_true, predicted) in enumerate(zip(y_true_list, predicted_images)):\n",
        "            overall_y_true[i].append(y_true)\n",
        "            overall_y_pred[i].append(predicted)\n",
        "\n",
        "        for i, prediction in enumerate(predicted_images):\n",
        "            plt.imshow(prediction.squeeze(), cmap='gray')\n",
        "            plt.title(f'Predicted Image {prediction_offsets[i]} Days Ahead for {station}')\n",
        "            plt.show()\n",
        "\n",
        "for i, offset in enumerate(prediction_offsets):\n",
        "    overall_y_true_np = np.array(overall_y_true[i])\n",
        "    overall_y_pred_np = np.array(overall_y_pred[i])\n",
        "    overall_r2 = r2_score(overall_y_true_np.reshape(len(overall_y_true_np), -1), overall_y_pred_np.reshape(len(overall_y_pred_np), -1))\n",
        "    overall_mse = mean_squared_error(overall_y_true_np.reshape(len(overall_y_true_np), -1), overall_y_pred_np.reshape(len(overall_y_pred_np), -1))\n",
        "    overall_mae = mean_absolute_error(overall_y_true_np.reshape(len(overall_y_true_np), -1), overall_y_pred_np.reshape(len(overall_y_pred_np), -1))\n",
        "    print(f\"Overall R² score for {offset} days ahead: {overall_r2:.4f}\")\n",
        "    print(f\"Overall MSE for {offset} days ahead: {overall_mse:.4f}\")\n",
        "    print(f\"Overall MAE for {offset} days ahead: {overall_mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN_Model**"
      ],
      "metadata": {
        "id": "Ptn-tDDi_GmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Input, TimeDistributed\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_tif_image(file_path, target_size=(128, 128)):\n",
        "    img = load_img(file_path, color_mode='grayscale', target_size=target_size)\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "    return img\n",
        "\n",
        "def load_dataset_from_directory(directory, target_size=(128, 128)):\n",
        "    images = []\n",
        "    dates = []\n",
        "    stations = []\n",
        "\n",
        "    for file_name in sorted(os.listdir(directory)):\n",
        "        if file_name.endswith('.tif'):\n",
        "            try:\n",
        "                station = file_name[:-15]\n",
        "                date_str = file_name[-14:-4]\n",
        "                date = datetime.strptime(date_str, '%Y-%m-%d')\n",
        "\n",
        "                img_path = os.path.join(directory, file_name)\n",
        "                print(f\"Loading image: {img_path}\")\n",
        "                img = load_tif_image(img_path, target_size=target_size)\n",
        "                images.append(img)\n",
        "                dates.append(date)\n",
        "                stations.append(station)\n",
        "            except ValueError as e:\n",
        "                print(f\"Skipping file {file_name}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(dates), np.array(stations)\n",
        "\n",
        "def prepare_data(images, sequence_length=10, prediction_offsets=[1, 3, 5]):\n",
        "    X = []\n",
        "    y_targets = [[] for _ in prediction_offsets]\n",
        "    for i in range(len(images) - sequence_length - max(prediction_offsets) + 1):\n",
        "        X.append(images[i:i + sequence_length])\n",
        "        for j, offset in enumerate(prediction_offsets):\n",
        "            y_targets[j].append(images[i + sequence_length + offset - 1])\n",
        "    return np.array(X), [np.array(y) for y in y_targets]\n",
        "\n",
        "def create_cnn_model(sequence_length, image_shape, num_predictions):\n",
        "    model_input = Input(shape=(sequence_length, *image_shape))\n",
        "\n",
        "    x = TimeDistributed(Conv2D(16, (3, 3), activation='relu'))(model_input)\n",
        "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
        "    x = TimeDistributed(Conv2D(32, (3, 3), activation='relu'))(x)\n",
        "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
        "    x = TimeDistributed(Flatten())(x)\n",
        "    x = TimeDistributed(Dense(128, activation='relu'))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "\n",
        "    outputs = []\n",
        "    for _ in range(num_predictions):\n",
        "        x_out = Dense(np.prod(image_shape), activation='sigmoid')(x)\n",
        "        output = Reshape(image_shape)(x_out)\n",
        "        outputs.append(output)\n",
        "\n",
        "    model = Model(inputs=model_input, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_next_images(model, input_sequence, num_predictions):\n",
        "    input_sequence = np.expand_dims(input_sequence, axis=0)\n",
        "    predicted_images = model.predict(input_sequence)\n",
        "    return [predicted.squeeze() for predicted in predicted_images]\n",
        "\n",
        "# Example usage\n",
        "directory = '/content/drive/MyDrive/Dataset_img/one_month_NO2_2019'\n",
        "stations = ['Delhi', 'Mumbai', 'Kolkata', 'Jaipur', 'Bengaluru', 'Bhopal', 'Chennai']\n",
        "target_size = (128, 128)\n",
        "sequence_length = 10\n",
        "prediction_offsets = [1, 3, 5]\n",
        "\n",
        "all_images, all_dates, all_stations = load_dataset_from_directory(directory, target_size=target_size)\n",
        "\n",
        "X, y_targets = prepare_data(all_images, sequence_length=sequence_length, prediction_offsets=prediction_offsets)\n",
        "\n",
        "image_shape = (128, 128, 1)\n",
        "num_predictions = len(prediction_offsets)\n",
        "model = create_cnn_model(sequence_length, image_shape, num_predictions)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model.fit(X, y_targets, epochs=12, batch_size=4, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "unique_stations = np.unique(all_stations)\n",
        "overall_y_true = [[] for _ in prediction_offsets]\n",
        "overall_y_pred = [[] for _ in prediction_offsets]\n",
        "\n",
        "for station in unique_stations:\n",
        "    station_indices = np.where(all_stations == station)[0]\n",
        "    if len(station_indices) > sequence_length + max(prediction_offsets) - 1:\n",
        "        index = station_indices[0]\n",
        "        input_sequence = X[index]\n",
        "        y_true_list = [y[index] for y in y_targets]\n",
        "        predicted_images = predict_next_images(model, input_sequence, num_predictions)\n",
        "\n",
        "        for i, (y_true, predicted) in enumerate(zip(y_true_list, predicted_images)):\n",
        "            overall_y_true[i].append(y_true)\n",
        "            overall_y_pred[i].append(predicted)\n",
        "\n",
        "        for i, prediction in enumerate(predicted_images):\n",
        "            plt.imshow(prediction.squeeze(), cmap='gray')\n",
        "            plt.title(f'Predicted Image {prediction_offsets[i]} Days Ahead for {station}')\n",
        "            plt.show()\n",
        "\n",
        "for i, offset in enumerate(prediction_offsets):\n",
        "    overall_y_true_np = np.array(overall_y_true[i])\n",
        "    overall_y_pred_np = np.array(overall_y_pred[i])\n",
        "    overall_r2 = r2_score(overall_y_true_np.reshape(len(overall_y_true_np), -1), overall_y_pred_np.reshape(len(overall_y_pred_np), -1))\n",
        "    overall_mse = mean_squared_error(overall_y_true_np.reshape(len(overall_y_true_np), -1), overall_y_pred_np.reshape(len(overall_y_pred_np), -1))\n",
        "    overall_mae = mean_absolute_error(overall_y_true_np.reshape(len(overall_y_true_np), -1), overall_y_pred_np.reshape(len(overall_y_pred_np), -1))\n",
        "    print(f\"Overall R² score for {offset} days ahead: {overall_r2:.4f}\")\n",
        "    print(f\"Overall MSE for {offset} days ahead: {overall_mse:.4f}\")\n",
        "    print(f\"Overall MAE for {offset} days ahead: {overall_mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "jLJuJz49_F6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN+LSTM**"
      ],
      "metadata": {
        "id": "yGUefltV_SH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Input, TimeDistributed, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_tif_image(file_path, target_size=(128, 128)):\n",
        "    img = load_img(file_path, color_mode='grayscale', target_size=target_size)\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "    return img\n",
        "\n",
        "def load_dataset_from_directory(directory, target_size=(128, 128)):\n",
        "    images = []\n",
        "    dates = []\n",
        "    stations = []\n",
        "\n",
        "    for file_name in sorted(os.listdir(directory)):\n",
        "        if file_name.endswith('.tif'):\n",
        "            try:\n",
        "                station = file_name[:-15]\n",
        "                date_str = file_name[-14:-4]\n",
        "                date = datetime.strptime(date_str, '%Y-%m-%d')\n",
        "\n",
        "                img_path = os.path.join(directory, file_name)\n",
        "                print(f\"Loading image: {img_path}\")\n",
        "                img = load_tif_image(img_path, target_size=target_size)\n",
        "                images.append(img)\n",
        "                dates.append(date)\n",
        "                stations.append(station)\n",
        "            except ValueError as e:\n",
        "                print(f\"Skipping file {file_name}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(dates), np.array(stations)\n",
        "\n",
        "def prepare_data(images, sequence_length=10, prediction_offsets=[1, 3, 5]):\n",
        "    X = []\n",
        "    y_targets = [[] for _ in prediction_offsets]\n",
        "    for i in range(len(images) - sequence_length - max(prediction_offsets) + 1):\n",
        "        X.append(images[i:i + sequence_length])\n",
        "        for j, offset in enumerate(prediction_offsets):\n",
        "            y_targets[j].append(images[i + sequence_length + offset - 1])\n",
        "    return np.array(X), [np.array(y) for y in y_targets]\n",
        "\n",
        "def create_cnn_lstm_model(sequence_length, image_shape, num_predictions):\n",
        "    model_input = Input(shape=(sequence_length, *image_shape))\n",
        "\n",
        "    x = TimeDistributed(Conv2D(16, (3, 3), activation='relu'))(model_input)\n",
        "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
        "    x = TimeDistributed(Conv2D(32, (3, 3), activation='relu'))(x)\n",
        "    x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
        "    x = TimeDistributed(Flatten())(x)\n",
        "\n",
        "    x = LSTM(128, return_sequences=True)(x)\n",
        "    x = LSTM(128)(x)\n",
        "\n",
        "    outputs = []\n",
        "    for _ in range(num_predictions):\n",
        "        x_out = Dense(np.prod(image_shape), activation='sigmoid')(x)\n",
        "        output = Reshape(image_shape)(x_out)\n",
        "        outputs.append(output)\n",
        "\n",
        "    model = Model(inputs=model_input, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_next_images(model, input_sequence, num_predictions):\n",
        "    input_sequence = np.expand_dims(input_sequence, axis=0)\n",
        "    predicted_images = model.predict(input_sequence)\n",
        "    return [predicted.squeeze() for predicted in predicted_images]\n",
        "\n",
        "# Example usage\n",
        "directory = '/content/drive/MyDrive/Dataset_img/one_month_NO2_2019'\n",
        "stations = ['Delhi', 'Mumbai', 'Kolkata', 'Jaipur', 'Bengaluru', 'Bhopal', 'Chennai']\n",
        "target_size = (128, 128)\n",
        "sequence_length = 10\n",
        "prediction_offsets = [1, 3, 5]\n",
        "\n",
        "all_images, all_dates, all_stations = load_dataset_from_directory(directory, target_size=target_size)\n",
        "\n",
        "X, y_targets = prepare_data(all_images, sequence_length=sequence_length, prediction_offsets=prediction_offsets)\n",
        "\n",
        "image_shape = (128, 128, 1)\n",
        "num_predictions = len(prediction_offsets)\n",
        "model = create_cnn_lstm_model(sequence_length, image_shape, num_predictions)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model.fit(X, y_targets, epochs=12, batch_size=4, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "unique_stations = np.unique(all_stations)\n",
        "overall_y_true = [[] for _ in prediction_offsets]\n",
        "overall_y_pred = [[] for _ in prediction_offsets]\n",
        "\n",
        "for station in unique_stations:\n",
        "    station_indices = np.where(all_stations == station)[0]\n",
        "    if len(station_indices) > sequence_length + max(prediction_offsets) - 1:\n",
        "        index = station_indices[0]\n",
        "        input_sequence = X[index]\n",
        "        y_true_list = [y[index] for y in y_targets]\n",
        "        predicted_images = predict_next_images(model, input_sequence, num_predictions)\n",
        "\n",
        "        for i, (y_true, predicted) in enumerate(zip(y_true_list, predicted_images)):\n",
        "            overall_y_true[i].append(y_true)\n",
        "            overall_y_pred[i].append(predicted)\n",
        "\n",
        "        for i, prediction in enumerate(predicted_images):\n",
        "            plt.imshow(prediction.squeeze(), cmap='gray')\n",
        "            plt.title(f'Predicted Image {prediction_offsets[i]} Days Ahead for {station}')\n",
        "            plt.show()\n",
        "\n",
        "for i, offset in enumerate(prediction_offsets):\n",
        "    overall_y_true_np = np.array(overall_y_true[i])\n",
        "    overall_y_pred_np = np.array(overall_y_pred[i])\n",
        "    overall_r2 = r2_score(overall_y_true_np.reshape(len(overall_y_true_np), -1), overall_y_pred_np.reshape(len(overall_y_pred_np), -1))\n",
        "    overall_mse = mean_squared_error(overall_y_true_np.reshape(len(overall_y_true_np), -1), overall_y_pred_np.reshape(len(overall_y_pred_np), -1))\n",
        "    overall_mae = mean_absolute_error(overall_y_true_np.reshape(len(overall_y_true_np), -1), overall_y_pred_np.reshape(len(overall_y_pred_np), -1))\n",
        "    print(f\"Overall R² score for {offset} days ahead: {overall_r2:.4f}\")\n",
        "    print(f\"Overall MSE for {offset} days ahead: {overall_mse:.4f}\")\n",
        "    print(f\"Overall MAE for {offset} days ahead: {overall_mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "Wd5KtoL8_WpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN+Transformer\n",
        "**Pediction All station**"
      ],
      "metadata": {
        "id": "ulSdMsHchTx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Input, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_tif_image(file_path, target_size=(128, 128)):\n",
        "    img = load_img(file_path, color_mode='grayscale', target_size=target_size)\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "    return img\n",
        "\n",
        "def load_dataset_from_directory(directory, target_size=(128, 128)):\n",
        "    images = []\n",
        "    dates = []\n",
        "    stations = []\n",
        "\n",
        "    for file_name in sorted(os.listdir(directory)):\n",
        "        if file_name.endswith('.tif'):\n",
        "            try:\n",
        "                station = file_name[:-15]\n",
        "                date_str = file_name[-14:-4]\n",
        "                date = datetime.strptime(date_str, '%Y-%m-%d')\n",
        "\n",
        "                img_path = os.path.join(directory, file_name)\n",
        "                print(f\"Loading image: {img_path}\")\n",
        "                img = load_tif_image(img_path, target_size=target_size)\n",
        "                images.append(img)\n",
        "                dates.append(date)\n",
        "                stations.append(station)\n",
        "            except ValueError as e:\n",
        "                print(f\"Skipping file {file_name}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(dates), np.array(stations)\n",
        "\n",
        "def prepare_data(images, sequence_length=10, prediction_offset=1):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(images) - sequence_length - prediction_offset + 1):\n",
        "        X.append(images[i:i + sequence_length])\n",
        "        y.append(images[i + sequence_length + prediction_offset - 1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    res = Add()([x, inputs])\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = Dense(inputs.shape[-1])(x)\n",
        "    return Add()([x, res])\n",
        "\n",
        "def create_cnn_transformer_model(sequence_length, image_shape, num_transformer_blocks=2, head_size=64, num_heads=2, ff_dim=64, dropout=0.1):\n",
        "    model_input = Input(shape=(sequence_length, *image_shape))\n",
        "\n",
        "    # CNN for feature extraction\n",
        "    cnn_features = []\n",
        "    for t in range(sequence_length):\n",
        "        x = Conv2D(16, kernel_size=(3, 3), activation='relu')(model_input[:, t])\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        x = Conv2D(32, kernel_size=(3, 3), activation='relu')(x)\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        cnn_features.append(x)\n",
        "\n",
        "    x = Concatenate()(cnn_features)\n",
        "    x = Reshape((sequence_length, -1))(x)\n",
        "\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x_out = Dense(np.prod(image_shape), activation='sigmoid')(x)\n",
        "    output = Reshape(image_shape)(x_out)\n",
        "\n",
        "    model = Model(inputs=model_input, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "def plot_image(img, title=''):\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "directory = '/content/drive/MyDrive/Dataset_img/one_month_NO2_2019'\n",
        "stations = ['Delhi', 'Mumbai', 'Kolkata', 'Jaipur', 'Bengaluru', 'Bhopal', 'Chennai']\n",
        "target_size = (128, 128)\n",
        "sequence_length = 10\n",
        "prediction_offsets = [1, 3, 5, 7]\n",
        "\n",
        "all_images, all_dates, all_stations = load_dataset_from_directory(directory, target_size=target_size)\n",
        "\n",
        "metrics = {'r2': [], 'mae': [], 'mse': [], 'rmse': []}\n",
        "\n",
        "for prediction_offset in prediction_offsets:\n",
        "    print(f\"Training for {prediction_offset}-day ahead prediction\")\n",
        "    X, y = prepare_data(all_images, sequence_length=sequence_length, prediction_offset=prediction_offset)\n",
        "\n",
        "    image_shape = (128, 128, 1)\n",
        "    model = create_cnn_transformer_model(sequence_length, image_shape)\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    model.fit(X, y, epochs=10, batch_size=4, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    y_true_flat = y.reshape((len(y), -1))\n",
        "    y_pred_flat = y_pred.reshape((len(y_pred), -1))\n",
        "\n",
        "    r2 = r2_score(y_true_flat, y_pred_flat)\n",
        "    mae = mean_absolute_error(y_true_flat, y_pred_flat)\n",
        "    mse = mean_squared_error(y_true_flat, y_pred_flat)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    metrics['r2'].append(r2)\n",
        "    metrics['mae'].append(mae)\n",
        "    metrics['mse'].append(mse)\n",
        "    metrics['rmse'].append(rmse)\n",
        "\n",
        "    print(f\"Metrics for {prediction_offset}-day ahead prediction:\")\n",
        "    print(f\"R² score: {r2:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"MSE: {mse:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "    # Plot an example prediction\n",
        "    # plot_image(y[0].squeeze(), title=f'True Image - {prediction_offset} days ahead')\n",
        "    # plot_image(y_pred[0].squeeze(), title=f'Predicted Image - {prediction_offset} days ahead')\n",
        "\n",
        "average_r2 = np.mean(metrics['r2'])\n",
        "average_mae = np.mean(metrics['mae'])\n",
        "average_mse = np.mean(metrics['mse'])\n",
        "average_rmse = np.mean(metrics['rmse'])\n",
        "\n",
        "print(\"Overall Metrics across all prediction offsets:\")\n",
        "print(f\"Overall R² score: {average_r2:.4f}\")\n",
        "print(f\"Overall MAE: {average_mae:.4f}\")\n",
        "print(f\"Overall MSE: {average_mse:.4f}\")\n",
        "print(f\"Overall RMSE: {average_rmse:.4f}\")\n"
      ],
      "metadata": {
        "id": "suBPUByQCcXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Input, Dropout, Add, Concatenate, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_tif_image(file_path, target_size=(128, 128)):\n",
        "    img = load_img(file_path, color_mode='grayscale', target_size=target_size)\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "    return img\n",
        "\n",
        "def load_dataset_from_directory(directory, target_size=(128, 128)):\n",
        "    images = []\n",
        "    dates = []\n",
        "    stations = []\n",
        "\n",
        "    for file_name in sorted(os.listdir(directory)):\n",
        "        if file_name.endswith('.tif'):\n",
        "            try:\n",
        "                station = file_name[:-15]\n",
        "                date_str = file_name[-14:-4]\n",
        "                date = datetime.strptime(date_str, '%Y-%m-%d')\n",
        "\n",
        "                img_path = os.path.join(directory, file_name)\n",
        "                print(f\"Loading image: {img_path}\")\n",
        "                img = load_tif_image(img_path, target_size=target_size)\n",
        "                images.append(img)\n",
        "                dates.append(date)\n",
        "                stations.append(station)\n",
        "            except ValueError as e:\n",
        "                print(f\"Skipping file {file_name}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(dates), np.array(stations)\n",
        "\n",
        "def prepare_data(images, sequence_length=10, prediction_offset=1):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(images) - sequence_length - prediction_offset + 1):\n",
        "        X.append(images[i:i + sequence_length])\n",
        "        y.append(images[i + sequence_length + prediction_offset - 1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def create_masknet_model(sequence_length, image_shape, dropout=0.1):\n",
        "    model_input = Input(shape=(sequence_length, *image_shape))\n",
        "\n",
        "    # CNN for feature extraction\n",
        "    cnn_features = []\n",
        "    for t in range(sequence_length):\n",
        "        x = Conv2D(16, kernel_size=(3, 3), activation='relu')(model_input[:, t])\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        x = Conv2D(32, kernel_size=(3, 3), activation='relu')(x)\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        cnn_features.append(x)\n",
        "\n",
        "    x = Concatenate()(cnn_features)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # MaskNet fully connected layers\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(dropout)(x)\n",
        "    x_out = Dense(np.prod(image_shape), activation='sigmoid')(x)\n",
        "    output = Reshape(image_shape)(x_out)\n",
        "\n",
        "    model = Model(inputs=model_input, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "def plot_image(img, title=''):\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "directory = '/content/drive/MyDrive/Dataset_img/one_month_NO2_2019'\n",
        "target_size = (128, 128)\n",
        "sequence_length = 10\n",
        "prediction_offsets = [1, 3, 5, 7]\n",
        "\n",
        "all_images, all_dates, all_stations = load_dataset_from_directory(directory, target_size=target_size)\n",
        "\n",
        "metrics = {'r2': [], 'mae': [], 'mse': [], 'rmse': []}\n",
        "\n",
        "for prediction_offset in prediction_offsets:\n",
        "    print(f\"Training for {prediction_offset}-day ahead prediction\")\n",
        "    X, y = prepare_data(all_images, sequence_length=sequence_length, prediction_offset=prediction_offset)\n",
        "\n",
        "    image_shape = (128, 128, 1)\n",
        "    model = create_masknet_model(sequence_length, image_shape)\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    model.fit(X, y, epochs=10, batch_size=4, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    y_true_flat = y.reshape((len(y), -1))\n",
        "    y_pred_flat = y_pred.reshape((len(y_pred), -1))\n",
        "\n",
        "    r2 = r2_score(y_true_flat, y_pred_flat)\n",
        "    mae = mean_absolute_error(y_true_flat, y_pred_flat)\n",
        "    mse = mean_squared_error(y_true_flat, y_pred_flat)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    metrics['r2'].append(r2)\n",
        "    metrics['mae'].append(mae)\n",
        "    metrics['mse'].append(mse)\n",
        "    metrics['rmse'].append(rmse)\n",
        "\n",
        "    print(f\"Metrics for {prediction_offset}-day ahead prediction:\")\n",
        "    print(f\"R² score: {r2:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"MSE: {mse:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "    # Plot an example prediction\n",
        "    # plot_image(y[0].squeeze(), title=f'True Image - {prediction_offset} days ahead')\n",
        "    # plot_image(y_pred[0].squeeze(), title=f'Predicted Image - {prediction_offset} days ahead')\n",
        "\n",
        "overall_r2 = np.mean(metrics['r2'])\n",
        "overall_mae = np.mean(metrics['mae'])\n",
        "overall_mse = np.mean(metrics['mse'])\n",
        "overall_rmse = np.mean(metrics['rmse'])\n",
        "\n",
        "print(\"Overall Metrics across all prediction offsets:\")\n",
        "print(f\"Overall R² score: {overall_r2:.4f}\")\n",
        "print(f\"Overall MAE: {overall_mae:.4f}\")\n",
        "print(f\"Overall MSE: {overall_mse:.4f}\")\n",
        "print(f\"Overall RMSE: {overall_rmse:.4f}\")\n"
      ],
      "metadata": {
        "id": "b7TJlENyeZK7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}